# Informe: Simulación de Fallas en Clúster Redis sobre Kubernetes

## Ejercicio 1: Simulación de caída de un pod del clúster Redis

### a. ¿Pudo identificar al pod que resolvía la petición? ¿Cuál era?

Sí, se identificó que el pod `redis-cluster-0` era el que resolvía las peticiones. Al eliminarlo, la mayoría de las solicitudes comenzaron a fallar, lo que indica que este pod actuaba como nodo maestro de la partición responsable de gestionar las claves utilizadas en las peticiones. Su caída generó un failover en el clúster.

### b. ¿Hubo algún otro pod que frente a la caída respondió de una manera particular? ¿Cuál? ¿Qué te parece que intentó hacer?

Sí, el pod `redis-cluster-4`, que era la réplica de `redis-cluster-0`, respondió intentando sincronizarse y ser promovido a maestro. En los logs se observa cómo perdió conexión con su maestro y luego fue promovido, iniciando intentos repetidos de conexión antes de estabilizarse. Esto es parte del mecanismo de alta disponibilidad del Redis Cluster.

### c. ¿Qué pasó con el tráfico y el reporte de Vegeta? ¿Se pudieron responder todas las peticiones?

Durante el apagado de `redis-cluster-0`, el reporte de Vegeta mostró una caída importante en la tasa de éxito: solo el **7.67%** de las peticiones fueron exitosas (`200 OK`), mientras que muchas fallaron con errores `500` o por tiempo de espera. Esto evidencia que, si bien el clúster intenta mantener disponibilidad, el failover no es inmediato y conlleva un período de inestabilidad.

**Extracto de Vegeta**:
```
Requests [total, rate, throughput]: 300, 5.02, 0.26  
Success [ratio]: 7.67%  
Status Codes: 0:261, 200:23, 500:16
```

### d. ¿Qué hizo Kubernetes luego de la simulación de la caída del pod?

Kubernetes detectó la caída del pod `redis-cluster-0` y procedió a reiniciarlo automáticamente. En paralelo, el clúster de Redis ejecutó su protocolo de failover para promover un nuevo nodo maestro. Este comportamiento garantiza una recuperación eventual del servicio, alineado con los principios de auto-recuperación de Kubernetes.

### e. ¿Qué pasó con los otros nodos del clúster?

Los demás nodos actualizaron su estado para reflejar el nuevo maestro (`redis-cluster-4`). Esta actualización incluyó el re-mapeo de slots y sincronización entre nodos. El protocolo de gossip del Redis Cluster permitió la redistribución de la carga y la información sobre el nuevo estado del clúster.

## Ejercicio 2: Simulación de caída de pods no respondientes

Se simuló la caída de pods no respondientes, y se observó que las solicitudes siguieron siendo procesadas correctamente. Los logs indican que las peticiones `GET` continuaron devolviendo código `200`, lo que demuestra que el clúster es capaz de tolerar fallas parciales y seguir operando si el nodo afectado no era crítico o si había una réplica disponible.

## Ejercicio 3: Análisis de arquitectura y consistencia del clúster Redis

### a. ¿Es un protocolo de replicación multi-master?

No. Aunque hay múltiples nodos maestros, el Redis Cluster no es multi-master en el sentido estricto. Cada clave pertenece a un único nodo maestro, y las operaciones no son replicadas entre ellos. En cambio, se implementa **sharding**, con cada maestro a cargo de un conjunto de slots. Las réplicas se usan para alta disponibilidad.

### b. ¿Por qué los nodos muestran logs ante un nuevo nodo?

Porque en Redis Cluster todos los nodos mantienen información del estado del clúster y se comunican mediante un **bus de clúster binario sobre TCP**, que permite el uso del protocolo **gossip**. Esta red permite la detección de fallos, sincronización entre réplicas y propagación de mensajes.

### c. ¿Qué protocolo de consistencia implementa?

Redis Cluster utiliza replicación **asíncrona**, combinada con un protocolo de gossip. Las réplicas pueden no estar completamente actualizadas cuando el maestro falla, lo cual puede generar pérdida de datos recientes. El failover promueve una réplica a maestro, aún si está desactualizada.

### d. ¿Modelo de consistencia?

El modelo de consistencia es **eventual**. Las operaciones pueden completarse con éxito desde el punto de vista del cliente, pero no necesariamente estar replicadas en todos los nodos en ese instante.

### e. ¿Arquitectura centrada en cliente o datos?

Redis Cluster utiliza una arquitectura **centrada en datos**, ya que las decisiones sobre qué nodo responde a una petición se basan en la distribución de las claves (slots) y la topología del clúster.

### f. Profundización sobre el modelo de consistencia en Redis

#### i. ¿Puede Redis cubrir el mismo caso de uso que una base de datos tradicional?

No completamente. Redis está diseñado para alto rendimiento y baja latencia en operaciones de lectura/escritura, a costa de sacrificar algunas garantías ACID, especialmente **consistencia fuerte** y **durabilidad**. Aunque puede usarse para muchos casos de uso como cachés o colas, no reemplaza a una base de datos relacional en aplicaciones críticas que requieran transacciones completas y persistencia garantizada.

#### ii. Diferencia entre strong consistency y weak consistency en Redis

- **Weak consistency** (por defecto): las réplicas pueden no reflejar de inmediato los cambios del maestro. Si este falla antes de replicar, los datos pueden perderse.
- **Strong consistency** (opcional): se puede usar el comando `WAIT`, que bloquea la respuesta hasta que al menos un número de réplicas confirme la escritura.